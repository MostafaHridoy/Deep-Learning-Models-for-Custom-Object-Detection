{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Augmentor"
      ],
      "metadata": {
        "id": "EhUeBkDtOfyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Augmentor\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Flatten, BatchNormalization, Dense, Dropout\n",
        "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "rXyNq75PPNDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/MyDrive/images.zip', 'r') as zipObj:\n",
        "\n",
        "   zipObj.extractall('IMAGES')"
      ],
      "metadata": {
        "id": "GobekDP4PkSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = Augmentor.Pipeline(\"/content/IMAGES/images\",output_directory=\"/content/output\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLaoxaB4P9PF",
        "outputId": "143733e0-2cf2-4dbe-caba-e77b3d80d7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 210 image(s) found.\n",
            "Output directory set to /content/output."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "\n",
        "p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)"
      ],
      "metadata": {
        "id": "Srp95kPUQA5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.sample(1000)"
      ],
      "metadata": {
        "id": "KuiUYeRlQFKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path('/content/output')\n",
        "img_height=224\n",
        "img_width=224"
      ],
      "metadata": {
        "id": "yR-JF8ihQKHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/output', 'zip', root_dir='/content/drive/MyDrive/Dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4pwqavK1QN-X",
        "outputId": "c12dacd6-dcf6-46e8-ef49-89dabb5c6663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMn7afRcQhke",
        "outputId": "f90dfeaa-fe12-4f1a-e650-1f6f82535c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 2 classes.\n",
            "Using 800 files for training.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Using 200 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
      ],
      "metadata": {
        "id": "IuAINEldQtGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = Rescaling(1./255)\n",
        "train_ds_normalized = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds_normalized = val_ds.map(lambda x, y: (normalization_layer(x), y))"
      ],
      "metadata": {
        "id": "5IQVoD1zQxba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=2"
      ],
      "metadata": {
        "id": "k23ObD6AREGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(x, y):\n",
        "    return x, tf.one_hot(y, depth=num_classes)\n",
        "\n",
        "train_ds_encoded = train_ds_normalized.map(one_hot_encoding)\n",
        "val_ds_encoded = val_ds_normalized.map(one_hot_encoding)"
      ],
      "metadata": {
        "id": "scCsaeTMQ0yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.nasnet import NASNetLarge, NASNetMobile\n",
        "from tensorflow.keras.applications.nasnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "Imm378wORzvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nasnet_large_model = NASNetLarge(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "ocvQYFCuSK50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in nasnet_large_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "bavIvVTKckP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = nasnet_large_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512,activation='relu')(x)\n",
        "x = Dense(256,activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "fyTD-eJCSU30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nasnet_large = Model(inputs=nasnet_large_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "9Z35lDrJThKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nasnet_large.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XirCcw9scAAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_nasnet_large.fit(\n",
        "    train_ds_encoded,\n",
        "    epochs=25,\n",
        "    validation_data=val_ds_encoded,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "ZmcggTexctSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "id": "p8sqGz-0eCym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zTmH4E0beLFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = np.concatenate([y for x, y in train_ds_encoded], axis=0)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhxOTuJ9fiGk",
        "outputId": "7bcd0fd3-fc38-4436-98b4-a2f3b1efaef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = np.concatenate([y for x, y in val_ds_normalized], axis=0)\n",
        "print(test_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mYeUEbofobA",
        "outputId": "534aa8c7-58d5-4499-f2ab-499fdc98fc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "Y_pred = model_nasnet_large.predict_generator(val_ds_normalized, 1600)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "cm=confusion_matrix(test_label, y_pred)\n",
        "print(cm)\n",
        "print('Classification Report')\n",
        "target_names = ['Pothole','SpeedBreaker']\n",
        "print(classification_report(test_label, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "nA47owq3frej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set(font_scale=1.0)\n",
        "ax=sns.heatmap(cm, annot=True, cmap='rocket', cbar=False, linewidths=3, linecolor='r', square=True, xticklabels=target_names,yticklabels=target_names,fmt='')\n",
        "sns.set(font_scale = 2.0)\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
        "ax.set_xlabel('\\nActual Values')\n",
        "ax.set_ylabel('Predicted Values ')"
      ],
      "metadata": {
        "id": "MdsTSFNXg14k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}