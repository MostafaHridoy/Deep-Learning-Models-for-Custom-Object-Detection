{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from tensorflow.keras.applications import EfficientNetB4, EfficientNetB5\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/New_Dataset.zip', 'r') as zipObj:\n",
        "    zipObj.extractall('IMAGES')\n",
        "\n",
        "data_dir = pathlib.Path('/content/IMAGES/New_Dataset')\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=8\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=8\n",
        ")\n",
        "\n",
        "normalization_layer = Rescaling(1./255)\n",
        "train_ds_normalized = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds_normalized = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "num_classes = 2\n",
        "def one_hot_encoding(x, y):\n",
        "    return x, tf.one_hot(y, depth=num_classes)\n",
        "\n",
        "train_ds_encoded = train_ds_normalized.map(one_hot_encoding)\n",
        "val_ds_encoded = val_ds_normalized.map(one_hot_encoding)\n",
        "\n",
        "train_ds_encoded = train_ds_encoded.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_ds_encoded = val_ds_encoded.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "base_model_b4 = EfficientNetB5(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x_b4 = base_model_b4.output\n",
        "x_b4 = GlobalAveragePooling2D()(x_b4)\n",
        "x_b4 = Dense(512, activation='relu')(x_b4)\n",
        "x_b4 = Dropout(0.20)(x_b4)\n",
        "x_b4 = Dense(256, activation='relu')(x_b4)\n",
        "output_b4 = Dense(num_classes, activation='softmax')(x_b4)\n",
        "model_efficientnet_b4 = Model(inputs=base_model_b4.input, outputs=output_b4)\n",
        "model_efficientnet_b4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "num_folds = 5\n",
        "fold_accuracies = []\n",
        "\n",
        "\n",
        "train_images, train_labels = tf.concat([x for x, y in train_ds_encoded], axis=0).numpy(), tf.concat([y for x, y in train_ds_encoded], axis=0).numpy()\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=123)\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(train_images)):\n",
        "    print(f\"Training Fold {fold+1}/{num_folds}\")\n",
        "\n",
        "\n",
        "    x_train, x_val = train_images[train_index], train_images[val_index]\n",
        "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
        "\n",
        "\n",
        "    train_ds_fold = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(16)\n",
        "    val_ds_fold = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(16)\n",
        "\n",
        "\n",
        "    model_efficientnet_b4.fit(\n",
        "        train_ds_fold,\n",
        "        epochs=25,\n",
        "        verbose=1,\n",
        "        validation_data=val_ds_fold\n",
        "    )\n",
        "\n",
        "\n",
        "    _, accuracy = model_efficientnet_b4.evaluate(val_ds_fold)\n",
        "    fold_accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "average_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
        "print(\"Average Accuracy: {:.2f}%\".format(average_accuracy * 100))\n"
      ],
      "metadata": {
        "id": "aK3437YZwlo6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}