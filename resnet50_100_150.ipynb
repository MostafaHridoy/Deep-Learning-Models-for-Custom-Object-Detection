{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS_43z5DALju",
        "outputId": "43c3b0ad-7b8e-43b3-cc55-da1eb1a6c5f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Augmentor in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (9.4.0)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from Augmentor) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG726M0eAzer"
      },
      "outputs": [],
      "source": [
        "import Augmentor\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Flatten, BatchNormalization, Dense, Dropout\n",
        "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axj74v1-A501"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/MyDrive/images.zip', 'r') as zipObj:\n",
        "\n",
        "   zipObj.extractall('IMAGES')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GioqfyzYBK-0",
        "outputId": "272252d7-66c6-43f2-e184-4e19de885ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialised with 210 image(s) found.\n",
            "Output directory set to /content/output."
          ]
        }
      ],
      "source": [
        "p = Augmentor.Pipeline(\"/content/IMAGES/images\",output_directory=\"/content/output\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMUsDSAjBR8D"
      },
      "outputs": [],
      "source": [
        "p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "\n",
        "p.zoom(probability=0.3, min_factor=1.1, max_factor=1.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "std28ez4BVc8",
        "outputId": "c5bbaf3e-bc07-4c20-8f57-4e43688b8905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing <PIL.Image.Image image mode=RGB size=816x460 at 0x7FEF59E7FD90>: 100%|██████████| 1000/1000 [00:47<00:00, 21.21 Samples/s]\n"
          ]
        }
      ],
      "source": [
        "p.sample(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tix3niEVBZbD"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path('/content/output')\n",
        "img_height=224\n",
        "img_width=224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PhIaPM26Bjit",
        "outputId": "ff8f1504-277d-44de-af6c-d60b9c6eedbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/output', 'zip', root_dir='/content/drive/MyDrive/Dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGIsPxbrBorv",
        "outputId": "415f1a06-af77-4c16-b306-c208a027d98f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Using 1600 files for training.\n",
            "Found 2000 files belonging to 2 classes.\n",
            "Using 400 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxPscwNRCF50"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLd-m3N_Byiw"
      },
      "outputs": [],
      "source": [
        "normalization_layer = Rescaling(1./255)\n",
        "train_ds_normalized = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds_normalized = val_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1AI7cF6Rg2-"
      },
      "outputs": [],
      "source": [
        "num_classes=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sHWyZw4D7dE"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoding(x, y):\n",
        "    return x, tf.one_hot(y, depth=num_classes)\n",
        "\n",
        "train_ds_encoded = train_ds_normalized.map(one_hot_encoding)\n",
        "val_ds_encoded = val_ds_normalized.map(one_hot_encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slVgd245EvKe"
      },
      "outputs": [],
      "source": [
        "train_ds_encoded = train_ds_encoded.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds_encoded = val_ds_encoded.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# Checkpoint to save best model per epoch\n",
        "\n",
        "model_filepath = \"/content/drive/My Drive/model-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=model_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "O5M2V6S453q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDuUIJrqCT6M"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2lQIT7gE8Du"
      },
      "outputs": [],
      "source": [
        "model_res50 = tf.keras.models.Sequential()\n",
        "model_res50.add(ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet'\n",
        "))\n",
        "\n",
        "model_res50.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model_res50.layers[0].trainable = False\n",
        "\n",
        "model_res50.summary()\n",
        "\n",
        "\n",
        "model_res50.compile(optimizer='adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history2 = model_res50.fit(\n",
        "    train_ds_encoded,\n",
        "    epochs=25,\n",
        "    validation_data=val_ds_encoded,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcXAdzq3Rr8e"
      },
      "outputs": [],
      "source": [
        "model_res50.save('model_res50.h5') #Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = np.concatenate([y for x, y in val_ds_normalized], axis=0)\n",
        "print(test_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL_2K1Nq4mNv",
        "outputId": "9244a7b3-e589-4532-db39-ca81cd910779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urHB5cnoag_P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history2.history['accuracy']\n",
        "val_acc = history2.history['val_accuracy']\n",
        "loss = history2.history['loss']\n",
        "val_loss = history2.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXKjs4xbak_G"
      },
      "outputs": [],
      "source": [
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "Y_pred = model_res50.predict_generator(val_ds_normalized, 1600)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "cm=confusion_matrix(test_label, y_pred)\n",
        "print(cm)\n",
        "print('Classification Report')\n",
        "target_names = ['Pothole','SpeedBreaker']\n",
        "print(classification_report(test_label, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "p7pTred35CwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set(font_scale=1.0)\n",
        "ax=sns.heatmap(cm, annot=True, cmap='rocket', cbar=False, linewidths=3, linecolor='r', square=True, xticklabels=target_names,yticklabels=target_names,fmt='')\n",
        "sns.set(font_scale = 2.0)\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
        "ax.set_xlabel('\\nActual Values')\n",
        "ax.set_ylabel('Predicted Values ')"
      ],
      "metadata": {
        "id": "yhknW-F75FtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MknZ6EmraofC"
      },
      "source": [
        "-------------------------------** *** ****END OF** **RESNET50**-------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_pLmTGnbY1B"
      },
      "source": [
        "------STARTING OF RESNET101------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibn1jT9nMHOE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc2SOk5ybewK"
      },
      "outputs": [],
      "source": [
        "model_res101 = tf.keras.models.Sequential()\n",
        "model_res101.add(ResNet101(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet'\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK5BtddAbtDe",
        "outputId": "849b0612-0f0c-4f55-bada-c31b8e90b898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet101 (Functional)      (None, 2048)              42658176  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,662,274\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 42,658,176\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_res101.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model_res101.layers[0].trainable = False\n",
        "\n",
        "model_res101.summary()\n",
        "\n",
        "# Compile the model\n",
        "model_res101.compile(optimizer='adam',\n",
        "                     loss='categorical_crossentropy',\n",
        "                     metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "CWVzTMZCbxCO",
        "outputId": "1bb76834-0c6c-4909-8605-381955912a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "50/50 [==============================] - 24s 302ms/step - loss: 0.6857 - accuracy: 0.5581 - val_loss: 0.6574 - val_accuracy: 0.5750\n",
            "Epoch 2/25\n",
            "50/50 [==============================] - 11s 213ms/step - loss: 0.6407 - accuracy: 0.6694 - val_loss: 0.6120 - val_accuracy: 0.7700\n",
            "Epoch 3/25\n",
            "50/50 [==============================] - 11s 216ms/step - loss: 0.6023 - accuracy: 0.7531 - val_loss: 0.5811 - val_accuracy: 0.7775\n",
            "Epoch 4/25\n",
            "50/50 [==============================] - 11s 218ms/step - loss: 0.5704 - accuracy: 0.7950 - val_loss: 0.5548 - val_accuracy: 0.7975\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-22208e1a16f1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history3 = model_res101.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1671\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m         \"\"\"Resets the state of all the metrics in the model.\n\u001b[1;32m   2430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history3 = model_res101.fit(\n",
        "    train_ds_encoded,\n",
        "    epochs=25,\n",
        "    validation_data=val_ds_encoded,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1tjtEGscWgP"
      },
      "outputs": [],
      "source": [
        "model_res101.save('model_resnet101.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJBFOT9NgdXr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history3.history['accuracy']\n",
        "val_acc = history3.history['val_accuracy']\n",
        "loss = history3.history['loss']\n",
        "val_loss = history3.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCF4GlTLgqtu"
      },
      "outputs": [],
      "source": [
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "Y_pred = model_res101.predict_generator(val_ds_normalized, 1600)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "cm=confusion_matrix(test_label, y_pred)\n",
        "print(cm)\n",
        "print('Classification Report')\n",
        "target_names = ['Pothole','SpeedBreaker']\n",
        "print(classification_report(test_label, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "sNTk1OHq4YYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set(font_scale=1.0)\n",
        "ax=sns.heatmap(cm, annot=True, cmap='rocket', cbar=False, linewidths=3, linecolor='r', square=True, xticklabels=target_names,yticklabels=target_names,fmt='')\n",
        "sns.set(font_scale = 2.0)\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
        "ax.set_xlabel('\\nActual Values')\n",
        "ax.set_ylabel('Predicted Values ')"
      ],
      "metadata": {
        "id": "w5ue3-n54uL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfS9AUWDfZS3"
      },
      "source": [
        "-------END OF RESNET-101-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqXML1Yufdyl"
      },
      "source": [
        "--------STARTING RESNET-152-------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i20GtktXcZ0d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5T9h9Tsfqtu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E94ZWpofxDI"
      },
      "outputs": [],
      "source": [
        "resnet152_model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "for layer in resnet152_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = resnet152_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x= Dropout(0.2)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwnuHN1_f-h3"
      },
      "outputs": [],
      "source": [
        "model_res152 = Model(inputs=resnet152_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTgW9GIjgC6_"
      },
      "outputs": [],
      "source": [
        "model_res152.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                     loss=CategoricalCrossentropy(),\n",
        "                     metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L0Lkgw7gaE3"
      },
      "outputs": [],
      "source": [
        "history4 = model_res152.fit(\n",
        "    train_ds_encoded,\n",
        "    epochs=25,\n",
        "    validation_data=val_ds_encoded,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6dmgM2ylHhf"
      },
      "outputs": [],
      "source": [
        "acc = history4.history['accuracy']\n",
        "val_acc = history4.history['val_accuracy']\n",
        "loss = history4.history['loss']\n",
        "val_loss = history4.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fP6QWoOlQgG"
      },
      "outputs": [],
      "source": [
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THS770HDsyHw"
      },
      "outputs": [],
      "source": [
        "model_res152.save(\"model_res152.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = np.concatenate([y for x, y in train_ds_encoded], axis=0)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "id": "EYTkviGx3mzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = np.concatenate([y for x, y in val_ds_normalized], axis=0)\n",
        "print(test_label.shape)"
      ],
      "metadata": {
        "id": "ofTGR3KJ3txo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "Y_pred = model_res152.predict_generator(val_ds_normalized, 2000)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "cm=confusion_matrix(test_label, y_pred)\n",
        "print(cm)\n",
        "print('Classification Report')\n",
        "target_names = ['Pothole','SpeedBreaker']\n",
        "print(classification_report(test_label, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "j9eCBVFA3xmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set(font_scale=1.0)\n",
        "ax=sns.heatmap(cm, annot=True, cmap='rocket', cbar=False, linewidths=3, linecolor='r', square=True, xticklabels=target_names,yticklabels=target_names,fmt='')\n",
        "sns.set(font_scale = 2.0)\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
        "ax.set_xlabel('\\nActual Values')\n",
        "ax.set_ylabel('Predicted Values ')"
      ],
      "metadata": {
        "id": "NkuF2obR3-Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENSEMBLED MODEL"
      ],
      "metadata": {
        "id": "bvMhVogh7-bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Average\n",
        "model_1 = load_model('/content/model_res50.h5')\n",
        "model_1 = Model(inputs=model_1.inputs,\n",
        "                outputs=model_1.outputs,\n",
        "                name='name_of_model_1')\n",
        "model_2 = load_model('/content/model_resnet101.h5')\n",
        "model_2 = Model(inputs=model_2.inputs,\n",
        "                outputs=model_2.outputs,\n",
        "                name='name_of_model_2')\n",
        "models = [model_1, model_2]\n",
        "model_input = Input(shape=(224, 224, 3))\n",
        "model_outputs = [model(model_input) for model in models]\n",
        "ensemble_output = Average()(model_outputs)\n",
        "ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')\n",
        "\n",
        "ensemble_model.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ID38zyPd5l3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history6=ensemble_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=25)"
      ],
      "metadata": {
        "id": "U3s_OKee6lSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history6.history['accuracy']\n",
        "val_acc = history6.history['val_accuracy']\n",
        "loss = history6.history['loss']\n",
        "val_loss = history6.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EFnhoUt06rP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = np.concatenate([y for x, y in train_ds], axis=0)\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "id": "-fVzfykL6x83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "print(test_label.shape)"
      ],
      "metadata": {
        "id": "x66Npa0L60Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "Y_pred = ensemble_model.predict_generator(val_ds, 1600)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "cm=confusion_matrix(test_label, y_pred)\n",
        "print(cm)\n",
        "print('Classification Report')\n",
        "target_names = ['Pothole','SpeedBreaker']\n",
        "print(classification_report(test_label, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "XhLVPPjS62av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.set(font_scale=1.0)\n",
        "ax=sns.heatmap(cm, annot=True, cmap='summer', cbar=False, linewidths=3, linecolor='r', square=True, xticklabels=target_names,yticklabels=target_names,fmt='')\n",
        "sns.set(font_scale = 2.0)\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n')\n",
        "ax.set_xlabel('\\nActual Values')\n",
        "ax.set_ylabel('Predicted Values ')"
      ],
      "metadata": {
        "id": "TUCvq0YK65xd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}