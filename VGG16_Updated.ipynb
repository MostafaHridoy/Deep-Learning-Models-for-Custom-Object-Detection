{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45p0q55DsrUs"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/vision_transformer.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the main dataset directory\n",
        "dataset_dir = \"/content/vision_transformer\"\n",
        "\n",
        "# Define the list of class names\n",
        "class_names = [\"Pothole\", \"speedbreaker\"]\n",
        "\n",
        "# Initialize lists to store images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through train, test, and valid subfolders\n",
        "for split in [\"train\", \"test\", \"valid\"]:\n",
        "    split_dir = os.path.join(dataset_dir, split)\n",
        "\n",
        "    # Iterate through class subfolders (pothole and speedbreaker)\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(split_dir, class_name)\n",
        "\n",
        "        # Get a list of image files in the class folder\n",
        "        image_files = glob.glob(os.path.join(class_dir, \"*.jpg\"))  # Adjust the file extension as needed\n",
        "\n",
        "        # Load and preprocess each image, and assign a label\n",
        "        for image_file in image_files:\n",
        "            img = load_img(image_file, target_size=(224, 224))  # Adjust target size as needed\n",
        "            img = img_to_array(img)\n",
        "            img = img / 255.0  # Normalize pixel values\n",
        "            images.append(img)\n",
        "\n",
        "            label = class_names.index(class_name)\n",
        "            labels.append(label)\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# One-hot encode labels if needed\n",
        "num_classes = len(class_names)\n",
        "one_hot_labels = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, one_hot_labels, test_size=0.2, random_state=42)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0V3EKkI_z4aY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten,Dense, SeparableConvolution2D\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "rN_psaUs0cgp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(224,224,3)"
      ],
      "metadata": {
        "id": "v3udDz5S0hwW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, SeparableConv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "\n",
        "def create_vgg16_new():\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = SeparableConv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = SeparableConv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = SeparableConv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    #x = BatchNormalization()(x)\n",
        "    x = SeparableConv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "    #x = Dropout(0.25)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    #x = BatchNormalization()(x)\n",
        "    x = SeparableConv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    #x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    #x = BatchNormalization()(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Output layer for classes (2 classes: Pothole and speedbreaker)\n",
        "    outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    # Creating the model\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "KL9hxkgT0XnP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model = create_vgg16_new()\n",
        "\n",
        "#Compile the model\n",
        "vgg16_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Wm4S4qCB0oD4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "acc_scores =[]\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, test_index in skf.split(images, labels):\n",
        "    X_train, X_test = images[train_index], images[test_index]\n",
        "    y_train, y_test = one_hot_labels[train_index], one_hot_labels[test_index]\n",
        "\n",
        "    # Train the model\n",
        "    vgg16_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = vgg16_model.predict(X_test)\n",
        "\n",
        "    # Convert one-hot encoded labels back to class labels for evaluation\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Calculate precision, recall, and F1-score for this fold\n",
        "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
        "    precision = precision_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "    recall = recall_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "    f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "\n",
        "    # Append the scores to the respective lists\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "    acc_scores.append(accuracy)\n",
        "\n",
        "# Calculate average precision, recall, and F1-score across all folds\n",
        "avg_precision = np.mean(precision_scores)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "avg_accuracy = np.mean(acc_scores)\n",
        "\n",
        "print(\"Average Accuracy : {:.2f}\".format(avg_accuracy))\n",
        "print(\"Average Precision: {:.2f}\".format(avg_precision))\n",
        "print(\"Average Recall: {:.2f}\".format(avg_recall))\n",
        "print(\"Average F1-score: {:.2f}\".format(avg_f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mKmA-0KU04c-",
        "outputId": "f29fdbcb-4ee8-460a-c142-4b39aab2f720"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "31/31 [==============================] - 42s 706ms/step - loss: 1.8441 - accuracy: 0.7711\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 21s 678ms/step - loss: 0.6931 - accuracy: 0.7918\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 20s 656ms/step - loss: 0.5775 - accuracy: 0.8278\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 20s 652ms/step - loss: 0.4546 - accuracy: 0.8670\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 20s 656ms/step - loss: 0.3469 - accuracy: 0.8856\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 21s 663ms/step - loss: 0.3998 - accuracy: 0.9000\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 21s 662ms/step - loss: 0.3786 - accuracy: 0.8814\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 20s 658ms/step - loss: 0.3552 - accuracy: 0.9082\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 20s 657ms/step - loss: 0.3007 - accuracy: 0.9072\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 20s 657ms/step - loss: 0.2098 - accuracy: 0.9247\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 20s 660ms/step - loss: 0.2744 - accuracy: 0.9216\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 20s 659ms/step - loss: 0.2446 - accuracy: 0.9392\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 20s 660ms/step - loss: 0.2961 - accuracy: 0.9299\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 20s 661ms/step - loss: 0.2423 - accuracy: 0.9278\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 20s 660ms/step - loss: 0.2700 - accuracy: 0.9330\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 21s 661ms/step - loss: 0.2243 - accuracy: 0.9433\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 20s 660ms/step - loss: 0.1245 - accuracy: 0.9649\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 20s 656ms/step - loss: 0.1396 - accuracy: 0.9680\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 20s 656ms/step - loss: 0.1743 - accuracy: 0.9629\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 20s 656ms/step - loss: 0.1429 - accuracy: 0.9660\n",
            "8/8 [==============================] - 3s 283ms/step\n",
            "Epoch 1/20\n",
            "31/31 [==============================] - 21s 663ms/step - loss: 0.3340 - accuracy: 0.9155\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 21s 680ms/step - loss: 0.2830 - accuracy: 0.9412\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 21s 662ms/step - loss: 0.1836 - accuracy: 0.9670\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 20s 652ms/step - loss: 0.2200 - accuracy: 0.9577\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 20s 656ms/step - loss: 0.1171 - accuracy: 0.9711\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 21s 664ms/step - loss: 0.0723 - accuracy: 0.9825\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 21s 665ms/step - loss: 0.0792 - accuracy: 0.9856\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 20s 657ms/step - loss: 0.0640 - accuracy: 0.9856\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 20s 659ms/step - loss: 0.0623 - accuracy: 0.9814\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 20s 657ms/step - loss: 0.0904 - accuracy: 0.9691\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 21s 661ms/step - loss: 0.0808 - accuracy: 0.9794\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 20s 660ms/step - loss: 0.0465 - accuracy: 0.9825\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 20s 658ms/step - loss: 0.0697 - accuracy: 0.9773\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 20s 657ms/step - loss: 0.1625 - accuracy: 0.9577\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 20s 657ms/step - loss: 0.1789 - accuracy: 0.9680\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 20s 658ms/step - loss: 0.0714 - accuracy: 0.9814\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 20s 660ms/step - loss: 0.0580 - accuracy: 0.9897\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 20s 660ms/step - loss: 0.0703 - accuracy: 0.9794\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 21s 662ms/step - loss: 0.0436 - accuracy: 0.9845\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 20s 659ms/step - loss: 0.0480 - accuracy: 0.9856\n",
            "8/8 [==============================] - 1s 126ms/step\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-83bbbad7e8ac>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mvgg16_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/dense_3/MatMul/MatMul_1' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n      ColabKernelApp.launch_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-15-83bbbad7e8ac>\", line 20, in <cell line: 15>\n      vgg16_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/model/dense_3/MatMul/MatMul_1'\nOOM when allocating tensor with shape[100352,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/dense_3/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7258]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "num_folds = 5\n",
        "\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "average_scores = [avg_accuracy, avg_precision, avg_recall, avg_f1]\n",
        "\n",
        "\n",
        "plt.plot(metrics, average_scores, marker='o', color='b', label='Average Scores')\n",
        "for i, metric_value in enumerate(average_scores):\n",
        "    plt.text(metrics[i], metric_value, f'{metric_value:.2f}', ha='center', va='bottom')\n",
        "\n",
        "\n",
        "for fold_idx in range(num_folds):\n",
        "    fold_scores = [acc_scores[fold_idx], precision_scores[fold_idx], recall_scores[fold_idx], f1_scores[fold_idx]]\n",
        "    plt.plot(metrics, fold_scores, marker='o', linestyle='--', label=f'Fold {fold_idx + 1}')\n",
        "    for i, metric_value in enumerate(fold_scores):\n",
        "        plt.text(metrics[i], metric_value, f'{metric_value:.2f}', ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Metrics Across Folds')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SGy9RTcN0-zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "ikb-1sfz1DwK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(vgg16_model, to_file='VGG16.png', show_shapes=True, dpi=300)"
      ],
      "metadata": {
        "id": "ptFlAErJ1G7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.save(\"VGG16.h5\")"
      ],
      "metadata": {
        "id": "juVydabt1Nn2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}